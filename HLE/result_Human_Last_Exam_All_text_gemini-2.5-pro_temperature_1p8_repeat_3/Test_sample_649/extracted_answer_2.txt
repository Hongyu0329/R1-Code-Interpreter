The tightest lower bound on \( R_n^* \) that can be proved using standard information-theoretic methods is
\[
\frac{1}{2} \Phi\left(\frac{\delta}{2}\right) \left(1 - d_{TV}\left(P_0^n, \frac{1}{N} \sum_{j=1}^N P_j^n\right)\right)
\]
where \( d_{TV}(P,Q) = \sup_{A} |P(A) - Q(A)| \) is the total variation distance between the probability measures \(P\) and \(Q\).